"""
ë‰´ìŠ¤/ìœ íŠœë¸Œ ìˆ˜ì§‘ ì‹œìŠ¤í…œ - Streamlit ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜
"""
import streamlit as st
import pandas as pd
from datetime import datetime, timedelta
import naver_collector
import youtube_collector


# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ARGOS-K",
    page_icon="ğŸ“°",
    layout="wide"
)

# CSS ìŠ¤íƒ€ì¼ë§
st.markdown("""
    <style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #e35d14;
        text-align: center;
        margin-bottom: 2rem;
    }
    .section-header {
        font-size: 1.5rem;
        font-weight: bold;
        color: #2c3e50;
        margin-top: 2rem;
        margin-bottom: 1rem;
        border-bottom: 2px solid #3498db;
        padding-bottom: 0.5rem;
    }
    .info-box {
        background-color: #e8f4f8;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #3498db;
        margin: 1rem 0;
    }
    .success-box {
        background-color: #d4edda;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #28a745;
        margin: 1rem 0;
    }
    .warning-box {
        background-color: #fff3cd;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #ffc107;
        margin: 1rem 0;
    }
    </style>
""", unsafe_allow_html=True)


def main():
    # í—¤ë”
    st.markdown('<div class="main-header">ARGOS-K</div>', unsafe_allow_html=True)
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'collected_data' not in st.session_state:
        st.session_state.collected_data = None
    if 'collection_stats' not in st.session_state:
        st.session_state.collection_stats = {}
    
    # ì‚¬ì´ë“œë°” - API í‚¤ ì…ë ¥
    with st.sidebar:
        st.markdown('<div class="section-header">ğŸ”‘ API í‚¤ ì„¤ì •</div>', unsafe_allow_html=True)
        
        st.markdown("#### ë„¤ì´ë²„ API")
        naver_client_id = st.text_input(
            "Client ID",
            type="password",
            help="ë„¤ì´ë²„ ê°œë°œì ì„¼í„°ì—ì„œ ë°œê¸‰ë°›ì€ Client ID"
        )
        naver_client_secret = st.text_input(
            "Client Secret",
            type="password",
            help="ë„¤ì´ë²„ ê°œë°œì ì„¼í„°ì—ì„œ ë°œê¸‰ë°›ì€ Client Secret"
        )
        
        st.markdown("#### ìœ íŠœë¸Œ API")
        youtube_api_key = st.text_input(
            "API Key",
            type="password",
            help="Google Cloud Consoleì—ì„œ ë°œê¸‰ë°›ì€ API Key"
        )
        
        st.markdown("---")
        
        # API í‚¤ ê²€ì¦
        if st.button("ğŸ” API í‚¤ ê²€ì¦", use_container_width=True):
            with st.spinner("API í‚¤ ê²€ì¦ ì¤‘..."):
                results = []
                
                if naver_client_id and naver_client_secret:
                    valid, msg = naver_collector.validate_api_key(naver_client_id, naver_client_secret)
                    results.append(msg)
                
                if youtube_api_key:
                    valid, msg = youtube_collector.validate_api_key(youtube_api_key)
                    results.append(msg)
                
                if results:
                    for result in results:
                        st.write(result)
                else:
                    st.warning("âš ï¸ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        st.markdown("---")
        
        # API ë°œê¸‰ ê°€ì´ë“œ
        with st.expander("ğŸ“˜ API í‚¤ ë°œê¸‰ ë°©ë²•"):
            st.markdown("""
            **ë„¤ì´ë²„ API**
            1. [ë„¤ì´ë²„ ê°œë°œì ì„¼í„°](https://developers.naver.com/) ì ‘ì†
            2. ë¡œê·¸ì¸ í›„ 'ì• í”Œë¦¬ì¼€ì´ì…˜ ë“±ë¡'
            3. ì‚¬ìš© APIì—ì„œ 'ê²€ìƒ‰' ì„ íƒ
            4. Client IDì™€ Secret ë³µì‚¬
            
            **ìœ íŠœë¸Œ API**
            1. [Google Cloud Console](https://console.cloud.google.com/) ì ‘ì†
            2. í”„ë¡œì íŠ¸ ìƒì„±
            3. 'YouTube Data API v3' í™œì„±í™”
            4. 'ì‚¬ìš©ì ì¸ì¦ ì •ë³´'ì—ì„œ API í‚¤ ìƒì„±
            """)
    
    # ë©”ì¸ ì½˜í…ì¸ 
    st.markdown('<div class="section-header">ğŸ” ê²€ìƒ‰ ì¡°ê±´ ì„¤ì •</div>', unsafe_allow_html=True)
    
    # ê²€ìƒ‰ ì¡°ê±´ ì…ë ¥
    col1, col2, col3 = st.columns([2, 1, 1])
    
    with col1:
        keyword = st.text_input(
            "ê²€ìƒ‰ í‚¤ì›Œë“œ",
            placeholder="ì˜ˆ: ì¤‘ëŒ€ì¬í•´, ì‚°ì—…ì¬í•´, ê±´ì„¤ì‚¬ê³  (ì‰¼í‘œë¡œ êµ¬ë¶„)",
            help="ì—¬ëŸ¬ í‚¤ì›Œë“œë¥¼ ì‰¼í‘œ(,)ë¡œ êµ¬ë¶„í•˜ì—¬ ì…ë ¥í•˜ë©´ OR ê²€ìƒ‰ íš¨ê³¼ (ì¤‘ë³µ ìë™ ì œê±°)"
        )
    
    with col2:
        start_date = st.date_input(
            "ì‹œì‘ì¼",
            value=datetime.now() - timedelta(days=30),
            help="ìˆ˜ì§‘ ì‹œì‘ ë‚ ì§œ"
        )
    
    with col3:
        end_date = st.date_input(
            "ì¢…ë£Œì¼",
            value=datetime.now(),
            help="ìˆ˜ì§‘ ì¢…ë£Œ ë‚ ì§œ"
        )
    
    # ìˆ˜ì§‘ ëŒ€ìƒ ì„ íƒ
    st.markdown("#### ğŸ“° ìˆ˜ì§‘ ëŒ€ìƒ ì„ íƒ")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        collect_naver = st.checkbox("ë„¤ì´ë²„ ë‰´ìŠ¤", value=True)
        if collect_naver:
            naver_max = st.number_input(
                "ìµœëŒ€ ìˆ˜ì§‘ ê±´ìˆ˜",
                min_value=10,
                max_value=1000,
                value=100,
                step=10,
                key="naver_max"
            )
    
    with col2:
        collect_youtube = st.checkbox("ìœ íŠœë¸Œ ì˜ìƒ", value=True)
        if collect_youtube:
            youtube_max = st.number_input(
                "ìµœëŒ€ ìˆ˜ì§‘ ê±´ìˆ˜",
                min_value=10,
                max_value=200,
                value=50,
                step=10,
                key="youtube_max"
            )
            youtube_channel_filter = st.checkbox(
                "ì–¸ë¡ ì‚¬ ì±„ë„ë§Œ",
                value=True,
                help="KBS, MBC, SBS, JTBC, TVì¡°ì„ , ì±„ë„A, MBN, ë‰´ìŠ¤1, ì—°í•©ë‰´ìŠ¤TV"
            )
    
    with col3:
        collect_comments = st.checkbox("ìœ íŠœë¸Œ ëŒ“ê¸€", value=True)
        if collect_comments:
            comments_per_video = st.number_input(
                "ì˜ìƒë‹¹ ëŒ“ê¸€ ìˆ˜",
                min_value=10,
                max_value=500,
                value=100,
                step=10,
                key="comments_max"
            )
    
    # ì •ë³´ ë°•ìŠ¤
    st.markdown('<div class="info-box">', unsafe_allow_html=True)
    st.markdown("""
    **ğŸ’¡ ìˆ˜ì§‘ íŒ**
    - ë„¤ì´ë²„ API: í•˜ë£¨ 25,000ê±´ ì œí•œ
    - ìœ íŠœë¸Œ API: í•˜ë£¨ 10,000 units ì œí•œ
    - ê°ìì˜ API í‚¤ë¥¼ ì‚¬ìš©í•˜ë©´ ë…ë¦½ì ì¸ í•œë„ ì ìš©
    - ìˆ˜ì§‘ ì‹œê°„ì€ ì„ íƒí•œ í•­ëª©ê³¼ ê±´ìˆ˜ì— ë”°ë¼ ë‹¬ë¼ì§‘ë‹ˆë‹¤
    - **ì—¬ëŸ¬ í‚¤ì›Œë“œ ì…ë ¥:** ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ë©´ ìë™ìœ¼ë¡œ í†µí•© (ì¤‘ë³µ ì œê±°)
    """)
    st.markdown('</div>', unsafe_allow_html=True)
    
    # API ì‚¬ìš©ëŸ‰ ì˜ˆì¸¡
    if keyword and (collect_naver or collect_youtube or collect_comments):
        keywords = [k.strip() for k in keyword.split(',') if k.strip()]
        num_keywords = len(keywords)
        
        st.markdown('<div class="warning-box">', unsafe_allow_html=True)
        st.markdown(f"**ğŸ“Š ì˜ˆìƒ API ì‚¬ìš©ëŸ‰ (í‚¤ì›Œë“œ {num_keywords}ê°œ)**")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if collect_naver:
                # ë„¤ì´ë²„: í•œ ë²ˆì˜ API í˜¸ì¶œ = 1ê±´
                # 100ê±´ì”© í˜ì´ì§•í•˜ë¯€ë¡œ (max/100)ë²ˆ í˜¸ì¶œ
                naver_calls = (naver_max // 100 + 1) * num_keywords
                naver_percent = (naver_calls / 25000) * 100
                st.write(f"**ë„¤ì´ë²„ API**")
                st.write(f"- ì•½ {naver_calls:,}íšŒ í˜¸ì¶œ")
                st.write(f"- ì¼ì¼ í•œë„ ëŒ€ë¹„: {naver_percent:.1f}%")
        
        with col2:
            if collect_youtube:
                # ìœ íŠœë¸Œ: ê²€ìƒ‰ 1íšŒ = 100 units
                youtube_units = 100 * num_keywords
                
                if collect_comments and youtube_max > 0:
                    # ëŒ“ê¸€ ì¡°íšŒ: 1ê°œ ì˜ìƒë‹¹ 1 unit
                    youtube_units += youtube_max * num_keywords
                
                youtube_percent = (youtube_units / 10000) * 100
                st.write(f"**ìœ íŠœë¸Œ API**")
                st.write(f"- ì•½ {youtube_units:,} units")
                st.write(f"- ì¼ì¼ í•œë„ ëŒ€ë¹„: {youtube_percent:.1f}%")
        
        st.markdown('</div>', unsafe_allow_html=True)
    
    # ìˆ˜ì§‘ ì‹œì‘ ë²„íŠ¼
    st.markdown("---")
    
    if st.button("ìˆ˜ì§‘ ì‹œì‘", type="primary", use_container_width=True):
        # ì…ë ¥ ê²€ì¦
        errors = []
        
        if not keyword:
            errors.append("ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        if start_date > end_date:
            errors.append("ì‹œì‘ì¼ì´ ì¢…ë£Œì¼ë³´ë‹¤ ëŠ¦ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        if collect_naver and (not naver_client_id or not naver_client_secret):
            errors.append("ë„¤ì´ë²„ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        if (collect_youtube or collect_comments) and not youtube_api_key:
            errors.append("ìœ íŠœë¸Œ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        if not collect_naver and not collect_youtube and not collect_comments:
            errors.append("ìµœì†Œ í•˜ë‚˜ì˜ ìˆ˜ì§‘ ëŒ€ìƒì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
        
        if errors:
            for error in errors:
                st.error(f"âŒ {error}")
        else:
            # í‚¤ì›Œë“œ íŒŒì‹±
            keywords = [k.strip() for k in keyword.split(',') if k.strip()]
            
            # ìˆ˜ì§‘ ì‹¤í–‰
            run_collection(
                keywords,
                start_date.strftime("%Y-%m-%d"),
                end_date.strftime("%Y-%m-%d"),
                collect_naver,
                collect_youtube,
                collect_comments,
                naver_client_id,
                naver_client_secret,
                youtube_api_key,
                naver_max if collect_naver else 0,
                youtube_max if collect_youtube else 0,
                youtube_channel_filter if collect_youtube else True,
                comments_per_video if collect_comments else 0
            )
    
    # ê²°ê³¼ í‘œì‹œ
    if st.session_state.collected_data is not None:
        display_results()


def run_collection(keywords, start_date, end_date, collect_naver, collect_youtube, 
                   collect_comments, naver_id, naver_secret, youtube_key,
                   naver_max, youtube_max, youtube_filter, comments_max):
    """ìˆ˜ì§‘ ì‹¤í–‰ - ë‹¤ì¤‘ í‚¤ì›Œë“œ ì§€ì›"""
    
    st.markdown('<div class="section-header">ğŸ“Š ìˆ˜ì§‘ ì§„í–‰ ìƒí™©</div>', unsafe_allow_html=True)
    
    # í‚¤ì›Œë“œ ì •ë³´ í‘œì‹œ
    if len(keywords) > 1:
        st.info(f"ğŸ” {len(keywords)}ê°œì˜ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰: {', '.join(keywords)}")
    
    all_data = []
    stats = {}
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    total_steps = len(keywords) * sum([collect_naver, collect_youtube, collect_comments])
    current_step = 0
    
    try:
        for keyword_idx, keyword in enumerate(keywords, 1):
            if len(keywords) > 1:
                st.markdown(f"**í‚¤ì›Œë“œ {keyword_idx}/{len(keywords)}: '{keyword}'**")
            
            # 1. ë„¤ì´ë²„ ë‰´ìŠ¤ ìˆ˜ì§‘
            if collect_naver:
                status_text.text(f"ğŸ“° ë„¤ì´ë²„ ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘... (í‚¤ì›Œë“œ: {keyword})")
                try:
                    naver_df = naver_collector.collect_naver_news(
                        naver_id, naver_secret, keyword, start_date, end_date, naver_max
                    )
                    if not naver_df.empty:
                        all_data.append(naver_df)
                    
                    if keyword_idx == 1:
                        stats['naver_news'] = len(naver_df)
                    else:
                        stats['naver_news'] = stats.get('naver_news', 0) + len(naver_df)
                    
                    st.success(f"âœ… '{keyword}' ë„¤ì´ë²„ ë‰´ìŠ¤: {len(naver_df)}ê±´")
                except Exception as e:
                    st.error(f"âŒ '{keyword}' ë„¤ì´ë²„ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
                
                current_step += 1
                progress_bar.progress(current_step / total_steps)
            
            # 2. ìœ íŠœë¸Œ ì˜ìƒ ìˆ˜ì§‘
            video_ids = []
            if collect_youtube:
                status_text.text(f"ğŸ¥ ìœ íŠœë¸Œ ì˜ìƒ ìˆ˜ì§‘ ì¤‘... (í‚¤ì›Œë“œ: {keyword})")
                try:
                    youtube_df = youtube_collector.collect_youtube_videos(
                        youtube_key, keyword, start_date, end_date, youtube_filter, youtube_max
                    )
                    if not youtube_df.empty:
                        all_data.append(youtube_df)
                        video_ids = youtube_df['video_id'].tolist()
                    
                    if keyword_idx == 1:
                        stats['youtube_videos'] = len(youtube_df)
                    else:
                        stats['youtube_videos'] = stats.get('youtube_videos', 0) + len(youtube_df)
                    
                    st.success(f"âœ… '{keyword}' ìœ íŠœë¸Œ ì˜ìƒ: {len(youtube_df)}ê±´")
                except Exception as e:
                    st.error(f"âŒ '{keyword}' ìœ íŠœë¸Œ ì˜ìƒ ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
                
                current_step += 1
                progress_bar.progress(current_step / total_steps)
            
            # 3. ìœ íŠœë¸Œ ëŒ“ê¸€ ìˆ˜ì§‘
            if collect_comments and video_ids:
                status_text.text(f"ğŸ’¬ ìœ íŠœë¸Œ ëŒ“ê¸€ ìˆ˜ì§‘ ì¤‘... (í‚¤ì›Œë“œ: {keyword})")
                try:
                    comments_df = youtube_collector.collect_youtube_comments(
                        youtube_key, video_ids, comments_max
                    )
                    if not comments_df.empty:
                        all_data.append(comments_df)
                    
                    if keyword_idx == 1:
                        stats['youtube_comments'] = len(comments_df)
                    else:
                        stats['youtube_comments'] = stats.get('youtube_comments', 0) + len(comments_df)
                    
                    st.success(f"âœ… '{keyword}' ìœ íŠœë¸Œ ëŒ“ê¸€: {len(comments_df)}ê±´")
                except Exception as e:
                    st.error(f"âŒ '{keyword}' ìœ íŠœë¸Œ ëŒ“ê¸€ ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
                
                current_step += 1
                progress_bar.progress(current_step / total_steps)
            elif collect_comments and not video_ids:
                st.warning(f"âš ï¸ '{keyword}': ìˆ˜ì§‘ëœ ì˜ìƒì´ ì—†ì–´ ëŒ“ê¸€ì„ ìˆ˜ì§‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                current_step += 1
                progress_bar.progress(current_step / total_steps)
        
        # ë°ì´í„° í†µí•© ë° ì¤‘ë³µ ì œê±°
        if all_data:
            combined_df = pd.concat(all_data, ignore_index=True)
            
            # ì¤‘ë³µ ì œê±°
            original_count = len(combined_df)
            
            # ê° íƒ€ì…ë³„ë¡œ ì¤‘ë³µ ì œê±° ê¸°ì¤€ ë‹¤ë¥´ê²Œ ì ìš©
            if 'type' in combined_df.columns:
                deduplicated_dfs = []
                
                # ë„¤ì´ë²„ ë‰´ìŠ¤: link ê¸°ì¤€
                if 'naver_news' in combined_df['type'].values:
                    naver_df = combined_df[combined_df['type'] == 'naver_news']
                    if 'link' in naver_df.columns:
                        naver_df = naver_df.drop_duplicates(subset=['link'], keep='first')
                    deduplicated_dfs.append(naver_df)
                
                # ìœ íŠœë¸Œ ì˜ìƒ: video_id ê¸°ì¤€
                if 'youtube_video' in combined_df['type'].values:
                    youtube_df = combined_df[combined_df['type'] == 'youtube_video']
                    if 'video_id' in youtube_df.columns:
                        youtube_df = youtube_df.drop_duplicates(subset=['video_id'], keep='first')
                    deduplicated_dfs.append(youtube_df)
                
                # ìœ íŠœë¸Œ ëŒ“ê¸€: comment_id ê¸°ì¤€
                if 'youtube_comment' in combined_df['type'].values:
                    comments_df = combined_df[combined_df['type'] == 'youtube_comment']
                    if 'comment_id' in comments_df.columns:
                        comments_df = comments_df.drop_duplicates(subset=['comment_id'], keep='first')
                    deduplicated_dfs.append(comments_df)
                
                combined_df = pd.concat(deduplicated_dfs, ignore_index=True)
            
            duplicate_count = original_count - len(combined_df)
            
            if duplicate_count > 0:
                st.info(f"ğŸ”„ ì¤‘ë³µ ì œê±°: {duplicate_count}ê±´ (ìµœì¢… {len(combined_df)}ê±´)")
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            if 'type' in combined_df.columns:
                stats['naver_news'] = len(combined_df[combined_df['type'] == 'naver_news'])
                stats['youtube_videos'] = len(combined_df[combined_df['type'] == 'youtube_video'])
                stats['youtube_comments'] = len(combined_df[combined_df['type'] == 'youtube_comment'])
            
            st.session_state.collected_data = combined_df
            st.session_state.collection_stats = stats
            
            status_text.text("âœ… ìˆ˜ì§‘ ì™„ë£Œ!")
            progress_bar.progress(1.0)
        else:
            st.warning("âš ï¸ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
    except Exception as e:
        st.error(f"âŒ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")


def display_results():
    """ê²°ê³¼ í‘œì‹œ"""
    
    st.markdown('<div class="section-header">ğŸ“Š ìˆ˜ì§‘ ê²°ê³¼</div>', unsafe_allow_html=True)
    
    df = st.session_state.collected_data
    stats = st.session_state.collection_stats
    
    # í†µê³„ í‘œì‹œ
    st.markdown('<div class="success-box">', unsafe_allow_html=True)
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ì´ ìˆ˜ì§‘ ê±´ìˆ˜", f"{len(df):,}")
    
    with col2:
        if 'naver_news' in stats:
            st.metric("ë„¤ì´ë²„ ë‰´ìŠ¤", f"{stats['naver_news']:,}")
    
    with col3:
        if 'youtube_videos' in stats:
            st.metric("ìœ íŠœë¸Œ ì˜ìƒ", f"{stats['youtube_videos']:,}")
    
    with col4:
        if 'youtube_comments' in stats:
            st.metric("ìœ íŠœë¸Œ ëŒ“ê¸€", f"{stats['youtube_comments']:,}")
    
    st.markdown('</div>', unsafe_allow_html=True)
    
    # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
    st.markdown("#### ğŸ“‹ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ìƒìœ„ 10ê°œ)")
    st.dataframe(df.head(10), use_container_width=True)
    
    # Excel íŒŒì¼ ìƒì„±
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"ìˆ˜ì§‘ê²°ê³¼_{timestamp}.xlsx"
    
    # BytesIO ê°ì²´ë¡œ Excel íŒŒì¼ ìƒì„±
    from io import BytesIO
    output = BytesIO()
    
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        # ë„¤ì´ë²„ ë‰´ìŠ¤ ì‹œíŠ¸
        if 'naver_news' in stats and stats['naver_news'] > 0:
            naver_df = df[df['type'] == 'naver_news'].copy()
            # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
            naver_columns = ['title', 'description', 'link', 'originallink', 'pubDate']
            naver_df = naver_df[[col for col in naver_columns if col in naver_df.columns]]
            naver_df.to_excel(writer, sheet_name='ë„¤ì´ë²„_ë‰´ìŠ¤', index=False)
            
            # ì»¬ëŸ¼ í­ ìë™ ì¡°ì •
            worksheet = writer.sheets['ë„¤ì´ë²„_ë‰´ìŠ¤']
            for idx, col in enumerate(naver_df.columns):
                max_length = max(
                    naver_df[col].astype(str).apply(len).max(),
                    len(str(col))
                )
                worksheet.column_dimensions[chr(65 + idx)].width = min(max_length + 2, 50)
        
        # ìœ íŠœë¸Œ ì˜ìƒ ì‹œíŠ¸
        if 'youtube_videos' in stats and stats['youtube_videos'] > 0:
            youtube_df = df[df['type'] == 'youtube_video'].copy()
            # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
            youtube_columns = ['title', 'description', 'channel_name', 'published_at', 
                             'view_count', 'like_count', 'comment_count', 'tags', 'url', 'video_id']
            youtube_df = youtube_df[[col for col in youtube_columns if col in youtube_df.columns]]
            youtube_df.to_excel(writer, sheet_name='ìœ íŠœë¸Œ_ì˜ìƒ', index=False)
            
            # ì»¬ëŸ¼ í­ ìë™ ì¡°ì •
            worksheet = writer.sheets['ìœ íŠœë¸Œ_ì˜ìƒ']
            for idx, col in enumerate(youtube_df.columns):
                max_length = max(
                    youtube_df[col].astype(str).apply(len).max(),
                    len(str(col))
                )
                worksheet.column_dimensions[chr(65 + idx)].width = min(max_length + 2, 50)
        
        # ìœ íŠœë¸Œ ëŒ“ê¸€ ì‹œíŠ¸
        if 'youtube_comments' in stats and stats['youtube_comments'] > 0:
            comments_df = df[df['type'] == 'youtube_comment'].copy()
            # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
            comments_columns = ['video_id', 'author', 'text', 'like_count', 'published_at']
            comments_df = comments_df[[col for col in comments_columns if col in comments_df.columns]]
            comments_df.to_excel(writer, sheet_name='ìœ íŠœë¸Œ_ëŒ“ê¸€', index=False)
            
            # ì»¬ëŸ¼ í­ ìë™ ì¡°ì •
            worksheet = writer.sheets['ìœ íŠœë¸Œ_ëŒ“ê¸€']
            for idx, col in enumerate(comments_df.columns):
                max_length = max(
                    comments_df[col].astype(str).apply(len).max(),
                    len(str(col))
                )
                worksheet.column_dimensions[chr(65 + idx)].width = min(max_length + 2, 50)
    
    excel_data = output.getvalue()
    
    # Excel ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
    st.download_button(
        label="ğŸ“¥ Excel ë‹¤ìš´ë¡œë“œ",
        data=excel_data,
        file_name=filename,
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        use_container_width=True,
        type="primary"
    )
    
    # ë°ì´í„° íƒ€ì…ë³„ ë¶„í¬
    if 'type' in df.columns:
        st.markdown("#### ğŸ“Š ë°ì´í„° íƒ€ì…ë³„ ë¶„í¬")
        type_counts = df['type'].value_counts()
        st.bar_chart(type_counts)


if __name__ == "__main__":
    main()
